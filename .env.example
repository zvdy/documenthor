# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=codellama:7b

# Alternative models you can use:
# OLLAMA_MODEL=llama2:7b
# OLLAMA_MODEL=mistral:7b
# OLLAMA_MODEL=documenthor:latest  # Your fine-tuned model
